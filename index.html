<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="AI架构师, ai infra, AI系统设计, AI系统优化, 机器学习, 深度学习, 大数据处理, 高性能AI架构, 可扩展AI系统, ChatGPT, Stable Diffusion, AI 绘画, 大模型">
  
  
    <meta name="description" content="这个网站旨在为AI架构师和对AI系统设计和优化感兴趣的人提供有价值的信息和资源。我们提供关于AI架构设计原理、机器学习和深度学习算法、大规模数据处理技术等方面的深入文章、案例研究和最佳实践指南。通过这些内容，我们希望帮助读者了解如何构建高性能、可扩展的AI架构，并提供实用的建议和方法来优化AI系统的性能和可靠性。无论是初学者还是有经验的专业人士，我们致力于为您提供有益的见解和实用的资源，以推动AI架构领域的发展和进步。">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <title> AI架构 | AI系统基础架构设计与优化</title>
  
    <link rel="apple-touch-icon" sizes="57x57" href="/images/webclip/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/images/webclip/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/images/webclip/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/images/webclip/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/images/webclip/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/images/webclip/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/images/webclip/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/webclip/apple-touch-icon-180x180.png">
    <link rel="apple-touch-icon" sizes="167x167" href="/images/webclip/apple-touch-icon-167x167.png">
  
  
    <link rel="shortcut icon" href="/images/favicon.ico">
  
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <main class="main">
    
	<header id="header" class="header header-absolute">

	<div class="container">
		<nav class="navbar d-flex align-items-center">
			<a class="brand" href="/">
				<img class="logo lazyload" data-src="/images/brand.svg" alt="AI架构 | AI系统基础架构设计与优化" role="img">
			</a>
			<ul class="main-nav">
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/">首页</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/stories">案例</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/archives">文章</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/about">关于</a>
  </li>
  
</ul>
		</nav>
		<a id="mobile-nav-toggle">
			<span class="mobile-nav-toggle-bar"></span>
			<span class="mobile-nav-toggle-bar"></span>
			<span class="mobile-nav-toggle-bar"></span>
		</a>
	</div>
</header>

    <section>
      <!-- Index -->

<div class="hero">
	<figure class="hero-figure">
		<img class="hero-figure-img" src="/images/banner/banner.jpg" alt="AI架构 | AI系统基础架构设计与优化">
		<figcaption>
			<div class="container">
				<div class="figure-inset">
					<h2 class="h1">深入AI架构的奥秘</h2>
					<p>创造卓越的智能解决方案</p>
				</div>
			</div>
		</figcaption>
		<div class="learn-more">
			<a class="anchor" href="#landingpage">
				<img id="landingpage" src="data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='24' height='24' fill='white' viewBox='0 0 16 16'><path d='M8 3a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 3zm4 8a4 4 0 0 1-8 0V5a4 4 0 1 1 8 0v6zM8 0a5 5 0 0 0-5 5v6a5 5 0 0 0 10 0V5a5 5 0 0 0-5-5z'/></svg>" alt="">
			</a>
		</div>
	</figure>
</div>


<section class="section py-5 bg-light">
  <div class="container">
    <!-- 
  Data Files: source/_data/culture.yml
-->
<div class="row">
  
</div>
  </div>
</section>


  <section class="section py-5 " id="">
    <div class="container">
      <div class="section-heading text-center mb-5">
        <h3>文章</h3>
        <p class="text-gray">汇聚热点话题 打造创新思路</p>
      </div>

      
        <div class="section-body">
          
  <div class="row flex-wrap">
    
      <div class="col-3">
        <article id="post-【转载】LangChain+ChatGLM2-6B搭建知识库" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">title: 【转载】LangChain+ChatGLM2-6B搭建知识库</span><br><span class="line">date: 2023-06-26 06:50:32</span><br><span class="line">tags: 大模型, ChatGLM2-6B</span><br></pre></td></tr></table></figure>

<p>本文来自博客园，原文链接：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/botai/p/LangChain_ChatGLM2-6B.html">https://www.cnblogs.com/botai/p/LangChain_ChatGLM2-6B.html</a></p>
<h2 id="ChatGLM2-6B-介绍"><a href="#ChatGLM2-6B-介绍" class="headerlink" title="ChatGLM2-6B 介绍"></a>ChatGLM2-6B 介绍</h2><p>ChatGLM2-6B 在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，引入了如下新特性：</p>
<ul>
<li>• <strong>更强大的性能</strong>：基于 ChatGLM 初代模型的开发经验，全面升级了基座模型。ChatGLM2-6B 使用了 GLM 的混合目标函数，经过了 1.4T 中英标识符的预训练与人类偏好对齐训练，评测结果显示，相比于初代模型，ChatGLM2-6B 在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%） 、BBH（+60%）等数据集上的性能取得了大幅度的提升，在同尺寸开源模型中具有较强的竞争力。</li>
</ul>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632435-1491933983.png" class="" title="图片">

<ul>
<li>• <strong>更长的上下文</strong>：基于 FlashAttention 技术，将基座模型的上下文长度（Context Length）由 ChatGLM-6B 的 2K 扩展到了 32K，并在对话阶段使用 8K 的上下文长度训练，允许更多轮次的对话。</li>
<li>• <strong>更高效的推理</strong>：基于 Multi-Query Attention 技术，ChatGLM2-6B 有更高效的推理速度和更低的显存占用：在官方的模型实现下，推理速度相比初代提升了 42%，INT4 量化下，6G 显存支持的对话长度由 1K 提升到了 8K。</li>
</ul>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632905-1098197173.png" class="" title="图片">

<ul>
<li>• <strong>更开放的协议</strong>：ChatGLM2-6B 权重对学术研究完全开放，在获得官方的书面许可后，亦<strong>允许商业使用</strong>。</li>
</ul>
<p>相比于初代模型，ChatGLM2-6B 多个维度的能力都取得了提升，以下是一些官方对比示例。</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632839-1115027413.png" class="" title="图片">

<p>总的来说，看起来效果还不错，下面跟着树先生一起来试试水~</p>
<p>本文我将分 3 步带着大家一起实操一遍，并与之前 ChatGLM-6B 进行对比。</p>
<ul>
<li>• ChatGLM2-6B 部署</li>
<li>• ChatGLM2-6B 微调</li>
<li>• LangChain + ChatGLM2-6B 构建个人专属知识库</li>
</ul>
<h2 id="ChatGLM2-6B-部署"><a href="#ChatGLM2-6B-部署" class="headerlink" title="ChatGLM2-6B 部署"></a>ChatGLM2-6B 部署</h2><p>这里我们还是白嫖阿里云的机器学习 PAI 平台，使用 A10 显卡，这部分内容之前文章中有介绍。</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4NDg5OTg1Mg==&mid=2247484248&idx=1&sn=711d8ea75fc825ae7a1ade82b6eb5f2f&scene=21#wechat_redirect">免费部署一个开源大模型 MOSS</a></p>
<p>环境准备好了以后，就可以开始准备部署工作了。</p>
<h3 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/THUDM/ChatGLM2-6B</span><br></pre></td></tr></table></figure>

<h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ChatGLM2-6B</span><br><span class="line"><span class="comment"># 其中 transformers 库版本推荐为 4.30.2，torch 推荐使用 2.0 及以上的版本，以获得最佳的推理性能</span></span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<h3 id="下载模型"><a href="#下载模型" class="headerlink" title="下载模型"></a>下载模型</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里我将下载的模型文件放到了本地的 chatglm-6b 目录下</span></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/THUDM/chatglm2-6b <span class="variable">$PWD</span>/chatglm2-6b</span><br></pre></td></tr></table></figure>

<h3 id="参数调整"><a href="#参数调整" class="headerlink" title="参数调整"></a>参数调整</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为前面改了模型默认下载地址，所以这里需要改下路径参数</span></span><br><span class="line"><span class="comment"># 修改 web_demo.py 文件</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;/mnt/workspace/chatglm2-6b&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">model = AutoModel.from_pretrained(<span class="string">&quot;/mnt/workspace/chatglm2-6b&quot;</span>, trust_remote_code=<span class="literal">True</span>).cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果想要本地访问，需要修改此处</span></span><br><span class="line">demo.queue().launch(share=<span class="literal">True</span>, inbrowser=<span class="literal">True</span>, server_name=<span class="string">&#x27;0.0.0.0&#x27;</span>, server_port=<span class="number">7860</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Web-模式启动"><a href="#Web-模式启动" class="headerlink" title="Web 模式启动"></a>Web 模式启动</h3><p>官方推荐用 Streamlit 启动会更流程一些，但受限于 PAI 平台没有分配弹性公网，所以还是用老的 gradio 启动吧。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python web_demo.py</span><br></pre></td></tr></table></figure>

<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632951-287181832.png" class="" title="图片">img

<h3 id="ChatGLM2-6B-对比-ChatGLM-6B"><a href="#ChatGLM2-6B-对比-ChatGLM-6B" class="headerlink" title="ChatGLM2-6B 对比 ChatGLM-6B"></a>ChatGLM2-6B 对比 ChatGLM-6B</h3><p>先让 ChatGPT 作为考官，出几道题。</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632967-1521522527.png" class="" title="图片">

<p>ChatGLM-6B 回答：</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632495-642956216.png" class="" title="图片">

<p>ChatGLM2-6B 回答：</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220633082-1769147658.png" class="" title="图片">

<p>明显可以看出，ChatGLM2-6B 相比于上一代模型响应速度更快，问题回答精确度更高，且拥有更长的（32K）上下文！</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632541-2120443628.png" class="" title="图片">

<h2 id="基于-P-Tuning-微调-ChatGLM2-6B"><a href="#基于-P-Tuning-微调-ChatGLM2-6B" class="headerlink" title="基于 P-Tuning 微调 ChatGLM2-6B"></a>基于 P-Tuning 微调 ChatGLM2-6B</h2><p>ChatGLM2-6B 环境已经有了，接下来开始模型微调，这里我们使用官方的 P-Tuning v2 对 ChatGLM2-6B 模型进行参数微调，P-Tuning v2 将需要微调的参数量减少到原来的 0.1%，再通过模型量化、Gradient Checkpoint 等方法，最低只需要 7GB 显存即可运行。</p>
<h3 id="安装依赖-1"><a href="#安装依赖-1" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行微调需要 4.27.1 版本的 transformers</span></span><br><span class="line">pip <span class="keyword">install </span>transformers==<span class="number">4</span>.<span class="number">27</span>.<span class="number">1</span></span><br><span class="line">pip <span class="keyword">install </span>rouge_chinese nltk <span class="keyword">jieba </span>datasets</span><br></pre></td></tr></table></figure>

<h3 id="禁用-W-amp-B"><a href="#禁用-W-amp-B" class="headerlink" title="禁用 W&amp;B"></a>禁用 W&amp;B</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 禁用 W&amp;B，如果不禁用可能会中断微调训练，以防万一，还是禁了吧</span></span><br><span class="line"><span class="built_in">export</span> WANDB_DISABLED=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h3><p>这里为了简化，我只准备了5条测试数据，分别保存为 train.json 和 dev.json，放到 ptuning 目录下，实际使用的时候肯定需要大量的训练数据。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;<span class="attribute">content</span>&quot;: <span class="string">&quot;你好，你是谁&quot;</span>, <span class="string">&quot;summary&quot;</span>: <span class="string">&quot;你好，我是树先生的助手小6。&quot;</span>&#125;</span><br><span class="line">&#123;&quot;<span class="attribute">content</span>&quot;: <span class="string">&quot;你是谁&quot;</span>, <span class="string">&quot;summary&quot;</span>: <span class="string">&quot;你好，我是树先生的助手小6。&quot;</span>&#125;</span><br><span class="line">&#123;&quot;<span class="attribute">content</span>&quot;: <span class="string">&quot;树先生是谁&quot;</span>, <span class="string">&quot;summary&quot;</span>: <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span>&#125;</span><br><span class="line">&#123;&quot;<span class="attribute">content</span>&quot;: <span class="string">&quot;介绍下树先生&quot;</span>, <span class="string">&quot;summary&quot;</span>: <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span>&#125;</span><br><span class="line">&#123;&quot;<span class="attribute">content</span>&quot;: <span class="string">&quot;树先生&quot;</span>, <span class="string">&quot;summary&quot;</span>: <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span>&#125;</span><br></pre></td></tr></table></figure>

<h3 id="参数调整-1"><a href="#参数调整-1" class="headerlink" title="参数调整"></a>参数调整</h3><p>修改 <code>train.sh</code> 和 <code>evaluate.sh</code> 中的 <code>train_file</code>、<code>validation_file</code>和<code>test_file</code>为你自己的 JSON 格式数据集路径，并将 <code>prompt_column</code> 和 <code>response_column</code> 改为 JSON 文件中输入文本和输出文本对应的 KEY。可能还需要增大 <code>max_source_length</code> 和 <code>max_target_length</code> 来匹配你自己的数据集中的最大输入输出长度。并将模型路径 <code>THUDM/chatglm2-6b</code> 改为你本地的模型路径。</p>
<h4 id="1、train-sh-文件修改"><a href="#1、train-sh-文件修改" class="headerlink" title="1、train.sh 文件修改"></a>1、train.sh 文件修改</h4><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">PRE_SEQ_LEN=<span class="number">32</span></span><br><span class="line">LR=<span class="number">2e-2</span></span><br><span class="line">NUM_GPUS=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">torchrun <span class="comment">--standalone --nnodes=1 --nproc-per-node=$NUM_GPUS main.py \</span></span><br><span class="line">    <span class="comment">--do_train \</span></span><br><span class="line">    <span class="comment">--train_file train.json \</span></span><br><span class="line">    <span class="comment">--validation_file dev.json \</span></span><br><span class="line">    <span class="comment">--preprocessing_num_workers 10 \</span></span><br><span class="line">    <span class="comment">--prompt_column content \</span></span><br><span class="line">    <span class="comment">--response_column summary \</span></span><br><span class="line">    <span class="comment">--overwrite_cache \</span></span><br><span class="line">    <span class="comment">--model_name_or_path /mnt/workspace/chatglm2-6b \</span></span><br><span class="line">    <span class="comment">--output_dir output/adgen-chatglm2-6b-pt-$PRE_SEQ_LEN-$LR \</span></span><br><span class="line">    <span class="comment">--overwrite_output_dir \</span></span><br><span class="line">    <span class="comment">--max_source_length 128 \</span></span><br><span class="line">    <span class="comment">--max_target_length 128 \</span></span><br><span class="line">    <span class="comment">--per_device_train_batch_size 1 \</span></span><br><span class="line">    <span class="comment">--per_device_eval_batch_size 1 \</span></span><br><span class="line">    <span class="comment">--gradient_accumulation_steps 16 \</span></span><br><span class="line">    <span class="comment">--predict_with_generate \</span></span><br><span class="line">    <span class="comment">--max_steps 3000 \</span></span><br><span class="line">    <span class="comment">--logging_steps 10 \</span></span><br><span class="line">    <span class="comment">--save_steps 1000 \</span></span><br><span class="line">    <span class="comment">--learning_rate $LR \</span></span><br><span class="line">    <span class="comment">--pre_seq_len $PRE_SEQ_LEN \</span></span><br><span class="line">    <span class="comment">--quantization_bit 4</span></span><br></pre></td></tr></table></figure>

<p><code>train.sh</code> 中的 <code>PRE_SEQ_LEN</code> 和 <code>LR</code> 分别是 soft prompt 长度和训练的学习率，可以进行调节以取得最佳的效果。P-Tuning-v2 方法会冻结全部的模型参数，可通过调整 <code>quantization_bit</code> 来改变原始模型的量化等级，不加此选项则为 FP16 精度加载。</p>
<h4 id="2、evaluate-sh-文件修改"><a href="#2、evaluate-sh-文件修改" class="headerlink" title="2、evaluate.sh 文件修改"></a>2、evaluate.sh 文件修改</h4><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PRE_SEQ_LEN=<span class="number">32</span></span><br><span class="line">CHECKPOINT=adgen-chatglm2<span class="number">-6</span>b-pt<span class="number">-32</span><span class="number">-2e-2</span></span><br><span class="line">STEP=<span class="number">3000</span></span><br><span class="line">NUM_GPUS=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">torchrun <span class="comment">--standalone --nnodes=1 --nproc-per-node=$NUM_GPUS main.py \</span></span><br><span class="line">    <span class="comment">--do_predict \</span></span><br><span class="line">    <span class="comment">--validation_file dev.json \</span></span><br><span class="line">    <span class="comment">--test_file dev.json \</span></span><br><span class="line">    <span class="comment">--overwrite_cache \</span></span><br><span class="line">    <span class="comment">--prompt_column content \</span></span><br><span class="line">    <span class="comment">--response_column summary \</span></span><br><span class="line">    <span class="comment">--model_name_or_path /mnt/workspace/chatglm2-6b \</span></span><br><span class="line">    <span class="comment">--ptuning_checkpoint ./output/$CHECKPOINT/checkpoint-$STEP \</span></span><br><span class="line">    <span class="comment">--output_dir ./output/$CHECKPOINT \</span></span><br><span class="line">    <span class="comment">--overwrite_output_dir \</span></span><br><span class="line">    <span class="comment">--max_source_length 128 \</span></span><br><span class="line">    <span class="comment">--max_target_length 128 \</span></span><br><span class="line">    <span class="comment">--per_device_eval_batch_size 1 \</span></span><br><span class="line">    <span class="comment">--predict_with_generate \</span></span><br><span class="line">    <span class="comment">--pre_seq_len $PRE_SEQ_LEN \</span></span><br><span class="line">    <span class="comment">--quantization_bit 4</span></span><br></pre></td></tr></table></figure>

<p><code>CHECKPOINT</code> 实际就是 <code>train.sh</code> 中的 <code>output_dir</code>。</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bash </span>train.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure>

<p>5 条数据大概训练了 50 分钟左右。</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220633066-1570481016.png" class="" title="图片">

<h3 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bash </span>evaluate.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure>

<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220633061-1802964012.png" class="" title="图片">

<p>执行完成后，会生成评测文件，评测指标为中文 Rouge score 和 BLEU-4。生成的结果保存在 .&#x2F;output&#x2F;adgen-chatglm2-6b-pt-32-2e-2&#x2F;generated_predictions.txt。我们准备了 5 条推理数据，所以相应的在文件中会有 5 条评测数据，labels 是 dev.json 中的预测输出，predict 是 ChatGLM2-6B 生成的结果，对比预测输出和生成结果，评测模型训练的好坏。如果不满意调整训练的参数再次进行训练。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;labels&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你好，我是树先生的助手小6。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;predict&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你好，我是树先生的助手小6。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;labels&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你好，我是树先生的助手小6。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;predict&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你好，我是树先生的助手小6。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;labels&quot;</span><span class="punctuation">:</span> <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;predict&quot;</span><span class="punctuation">:</span> <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;labels&quot;</span><span class="punctuation">:</span> <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;predict&quot;</span><span class="punctuation">:</span> <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;labels&quot;</span><span class="punctuation">:</span> <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;predict&quot;</span><span class="punctuation">:</span> <span class="string">&quot;树先生是一个程序员，热衷于用技术探索商业价值，持续努力为粉丝带来价值输出，运营公众号《程序员树先生》。&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="部署微调后的模型"><a href="#部署微调后的模型" class="headerlink" title="部署微调后的模型"></a>部署微调后的模型</h3><p>这里我们先修改 web_demo.sh 的内容以符合实际情况，将 <code>pre_seq_len</code> 改成你训练时的实际值，将 <code>THUDM/chatglm2-6b</code> 改成本地的模型路径。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PRE_SEQ_LEN=32</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=0 python3 web_demo.py \</span><br><span class="line">    --model_name_or_path /mnt/workspace/chatglm2-6b \</span><br><span class="line">    --ptuning_checkpoint output/adgen-chatglm2-6b-pt-32-2e-2/checkpoint-3000 \</span><br><span class="line">    --pre_seq_len <span class="variable">$PRE_SEQ_LEN</span></span><br></pre></td></tr></table></figure>

<p>然后再执行。</p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bash </span>web_demo.<span class="keyword">sh</span></span><br></pre></td></tr></table></figure>

<h3 id="结果对比"><a href="#结果对比" class="headerlink" title="结果对比"></a>结果对比</h3><h4 id="原始模型"><a href="#原始模型" class="headerlink" title="原始模型"></a>原始模型</h4><img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220633070-939675307.png" class="" title="图片">

<h4 id="微调后模型"><a href="#微调后模型" class="headerlink" title="微调后模型"></a>微调后模型</h4><img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220633099-1579471952.png" class="" title="图片">

<h2 id="LangChain-ChatGLM2-6B-构建知识库"><a href="#LangChain-ChatGLM2-6B-构建知识库" class="headerlink" title="LangChain + ChatGLM2-6B 构建知识库"></a>LangChain + ChatGLM2-6B 构建知识库</h2><h3 id="LangChain-知识库技术原理"><a href="#LangChain-知识库技术原理" class="headerlink" title="LangChain 知识库技术原理"></a>LangChain 知识库技术原理</h3><p>目前市面上绝大部分知识库都是 LangChain + LLM + embedding 这一套，实现原理如下图所示，过程包括加载文件 -&gt; 读取文本 -&gt; 文本分割 -&gt; 文本向量化 -&gt; 问句向量化 -&gt; 在文本向量中匹配出与问句向量最相似的<code>top k</code>个 -&gt; 匹配出的文本作为上下文和问题一起添加到 prompt 中 -&gt; 提交给 LLM 生成回答。</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632909-1342948348.png" class="" title="图片">

<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632518-1835023463.png" class="" title="图片">

<p>从上面就能看出，其核心技术就是向量 embedding，将用户知识库内容经过 embedding 存入向量知识库，然后用户每一次提问也会经过 embedding，利用向量相关性算法（例如余弦算法）找到最匹配的几个知识库片段，将这些知识库片段作为上下文，与用户问题一起作为 promt 提交给 LLM 回答，很好理解吧。一个典型的 prompt 模板如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">已知信息：</span></span><br><span class="line"><span class="string">&#123;context&#125; </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">根据上述已知信息，简洁和专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 </span></span><br><span class="line"><span class="string">问题是：&#123;question&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>更多关于向量 embedding 的内容可以参考我之前写的一篇文章。</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4NDg5OTg1Mg==&mid=2247484333&idx=1&sn=213a245558ba7b52e5736682a2ec45a9&chksm=cfb06acef8c7e3d8b08099a29d93891d455f4d7c6cc4dd72ea391b23a183bb09bcdb880a2423&scene=21#wechat_redirect">ChatGPT 引爆向量数据库赛道</a></p>
<h3 id="项目部署"><a href="#项目部署" class="headerlink" title="项目部署"></a>项目部署</h3><p><strong>下载源码</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/imClumsyPanda/langchain-ChatGLM.git</span><br></pre></td></tr></table></figure>

<p><strong>安装依赖</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> langchain-ChatGLM</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<p><strong>下载模型</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 git lfs</span></span><br><span class="line">git lfs install</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 LLM 模型</span></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/THUDM/chatglm2-6b <span class="variable">$PWD</span>/chatglm2-6b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 Embedding 模型</span></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/GanymedeNil/text2vec-large-chinese <span class="variable">$PWD</span>/text2vec</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型需要更新时，可打开模型所在文件夹后拉取最新模型文件/代码</span></span><br><span class="line">git pull</span><br></pre></td></tr></table></figure>

<p><strong>参数调整</strong></p>
<p>模型下载完成后，请在 <code>configs/model_config.py</code> 文件中，对<code>embedding_model_dict</code>和<code>llm_model_dict</code>参数进行修改。</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">embedding_model_dict = &#123;</span><br><span class="line">    <span class="string">&quot;ernie-tiny&quot;</span>: <span class="string">&quot;nghuyong/ernie-3.0-nano-zh&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ernie-base&quot;</span>: <span class="string">&quot;nghuyong/ernie-3.0-base-zh&quot;</span>,</span><br><span class="line">    <span class="string">&quot;text2vec-base&quot;</span>: <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>,</span><br><span class="line">    <span class="string">&quot;text2vec&quot;</span>: <span class="string">&quot;/mnt/workspace/text2vec&quot;</span>,</span><br><span class="line">    <span class="string">&quot;m3e-small&quot;</span>: <span class="string">&quot;moka-ai/m3e-small&quot;</span>,</span><br><span class="line">    <span class="string">&quot;m3e-base&quot;</span>: <span class="string">&quot;moka-ai/m3e-base&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">llm_model_dict = &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="string">&quot;chatglm2-6b&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;chatglm2-6b&quot;</span>,</span><br><span class="line">        <span class="string">&quot;pretrained_model_name&quot;</span>: <span class="string">&quot;/mnt/workspace/chatglm2-6b&quot;</span>,</span><br><span class="line">        <span class="string">&quot;local_model_path&quot;</span>: None,</span><br><span class="line">        <span class="string">&quot;provides&quot;</span>: <span class="string">&quot;ChatGLM&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># LLM 名称改成 chatglm2-6b</span></span><br><span class="line">LLM_MODEL = <span class="string">&quot;chatglm2-6b&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="项目启动"><a href="#项目启动" class="headerlink" title="项目启动"></a>项目启动</h3><p><strong>Web 模式启动</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python webui.py</span><br></pre></td></tr></table></figure>

<p>如果报了这个错：</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632966-402914823.png" class="" title="图片">

<p>升级下 protobuf 即可。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install <span class="comment">--upgrade protobuf==3.19.6</span></span><br></pre></td></tr></table></figure>

<p>启动成功！</p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632524-1702966774.png" class="" title="图片">

<p><strong>模型配置</strong></p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632543-184630604.png" class="" title="图片">

<p><strong>上传知识库</strong></p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632952-239703160.png" class="" title="图片">

<p><strong>基于</strong> <strong>ChatGLM2-6B 的知识库问答</strong></p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632941-638928516.png" class="" title="图片">

<h3 id="定制-UI"><a href="#定制-UI" class="headerlink" title="定制 UI"></a><strong>定制</strong> <strong>UI</strong></h3><p>由于 LangChain 项目更新了接口，树先生之前开发的定制 UI 也同步更新进行了适配。</p>
<p><strong>选择知识库</strong></p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632525-1874686678.png" class="" title="图片">

<p><strong>基于知识库问答</strong></p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632893-1731487740.png" class="" title="图片">

<p><strong>显示答案来源</strong></p>
<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220632499-811642262.png" class="" title="图片">

<img src="/2023/07/16/%E3%80%90%E8%BD%AC%E8%BD%BD%E3%80%91LangChain+ChatGLM2-6B%E6%90%AD%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%BA%93/3132769-20230715220633092-2050305602.png" class="" title="图片">

<p>好了，这一篇还挺长的，不过很多内容之前文章中都有提到，相当于是一篇 LangChain + LLM + embedding 构建知识库的<strong>总结篇</strong>了，大家收藏好这一篇就行了~</p>
<p>本文来自博客园，原文链接：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/botai/p/LangChain_ChatGLM2-6B.html">https://www.cnblogs.com/botai/p/LangChain_ChatGLM2-6B.html</a></p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-提示工程" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      <p>最近兴起的大型语言模型 (LLM)，例如 GPT-3、ChatGPT、AI21 的 Jurassic 和 Cohere，彻底改变了人工智能所能实现的目标。这些模型经过大量文本的训练，如果使用得当，可以回答问题、生成营销内容、总结会议记录、编写代码等等。</p>
<p>与法学硕士的交互与传统的机器学习模型有很大不同。我们提供文本提示作为 LLM 完成特定任务的说明，依靠其对大型数据集的预训练为我们提供准确的答案。</p>


<p>这些指令称为<strong>提示。</strong>提示是LLM的输入，其目的是告诉LLM该做什么或如何思考问题，以获得尽可能最佳和最准确的任务输出。调整提示以获得LLM更具体&#x2F;可用的答复称为<strong>提示工程</strong>，是一项关键技能；这是使用LLM的最大努力部分。</p>
<h1 id="在提示中包含直接说明"><a href="#在提示中包含直接说明" class="headerlink" title="在提示中包含直接说明"></a>在提示中包含直接说明</h1><p>让我们举一个简单的例子，要求 GPT-3（经过指令调整）将一个句子从英语翻译成西班牙语。我们的提示将包含三个元素：</p>
<ol>
<li>清晰、简洁、直接的指示：“**Translate.**”</li>
<li>我们要翻译的英语短语前面带有“ <strong>English:</strong> ”</li>
<li>明确指定供法学硕士回答的空间，前面有故意相似的前缀“<strong>Spanish:</strong> ”</li>
</ol>




<h1 id="在提示中举例以获得最佳回应"><a href="#在提示中举例以获得最佳回应" class="headerlink" title="在提示中举例以获得最佳回应"></a>在提示中举例以获得最佳回应</h1><p>如果清晰和直接的指示不足以一致和准确地解决任务，那么为LLM提供一些例子通常是个好主意。</p>
<p>让我们看一个英语到西班牙语翻译任务的示例。我们将用一个英语到西班牙语翻译的示例来替换指令“翻译”。我们应该以与最后一对完全相同的方式格式化示例，除了我们的示例将填写西班牙语翻译，以告诉LLM我们正在尝试做什么。</p>


<p>少量学习可以帮助澄清任务，尤其有助于语气、语法或风格等方面。这里一个翻译示例足以让模型正确响应。</p>
<p>我们可以看到，通过给模型提供我们想要的示例，模型可以计算出任务，就像我们给它一组直接指令一样。在提示中包含示例称为<strong>小样本学习。</strong>这是 GPT-3 的突破性功能，它是其研究论文标题的主要焦点：“语言模型是小样本学习器”。GPT-3 的创建者知道，小样本学习非常强大，它将成为人们与模型交互的主要方式之一。</p>
<h1 id="将提示说明与任务的最终目标保持一致"><a href="#将提示说明与任务的最终目标保持一致" class="headerlink" title="将提示说明与任务的最终目标保持一致"></a>将提示说明与任务的最终目标保持一致</h1><p>在设计提示时，我们需要设身处地为 LLM 着想并询问：模型认为我的任务的最终目标是什么？</p>
<p>例如，如果我们希望模型以友好的方式对客户做出单一响应，我们可以编写如下提示：</p>


<p>我们可以看到，GPT-3 认为任务是根据客户的初始输入创建完整的对话记录，而不仅仅是只回复客户一次。GPT-3不一定是错误的，但它与最初的具体任务意图不一致。让我们将提示更改为“以礼貌、乐于助人的客户服务代理的身份响应客户。”。</p>


<p>将提示更改为“回复…”更符合我们希望从LLM获得的最终目标。</p>
<p>从“这是一次对话……”到“响应……”的微小变化使 GPT-3 的响应与我们期望的结果保持一致。提示必须直接且适合任务；当它们不正确时，无论我们的意图如何，模型都会以它认为正确的任务来响应。</p>
<h1 id="使用角色获得更具体的声音"><a href="#使用角色获得更具体的声音" class="headerlink" title="使用角色获得更具体的声音"></a>使用角色获得更具体的声音</h1><p>在上一个示例中，我们希望 GPT-3 作为礼貌且乐于助人的客户服务代理来响应客户。“礼貌”和“乐于助人”等术语的使用引导模型的响应风格，促使其以某种角色进行响应。我们可以对这些项进行实验，看看它如何影响模型的响应。让我们将“礼貌、乐于助人”更改为“粗鲁”，并观察模型的反应。</p>


<p>我们甚至可以要求模型以名人或流行的虚构人物的身份进行回应。</p>
<h1 id="在提示中包含可接受的响应以保持一致性"><a href="#在提示中包含可接受的响应以保持一致性" class="headerlink" title="在提示中包含可接受的响应以保持一致性"></a>在提示中包含可接受的响应以保持一致性</h1>



<p>让我们引导 GPT-3 仅响应“肯定”或“否定”。</p>
<h1 id="尝试不同的提示以找到最有效的"><a href="#尝试不同的提示以找到最有效的" class="headerlink" title="尝试不同的提示以找到最有效的"></a>尝试不同的提示以找到最有效的</h1><p>我们可以继续提供更多有关如何设计提示的提示和技巧，但让您继续前进的最佳方法是尝试相同基本提示的变体，看看哪种最有效。例如：</p>
<ol>
<li>当尝试少样本学习时，也尝试包括直接指令</li>
<li>将直接指令集改写为或多或少简洁（例如，以我们之前仅说“翻译”的示例为例，然后扩展指令以说“从英语翻译成西班牙语”。</li>
<li>尝试不同的角色关键字，看看它如何影响响应风格</li>
<li>在几次学习中使用更少或更多的例子</li>
</ol>
<h1 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h1><p>我们已经看到了一些快速工程入门的技巧。快速回顾一下：</p>
<ol>
<li>使用清晰、直接、简洁的说明</li>
<li>尝试“完成这句话”提示以获得更自然的反应</li>
<li>使用任务的示例（小样本学习）</li>
<li>将提示说明与明确的最终目标保持一致</li>
<li>使用角色关键字来改变响应的风格和语气</li>
<li>通过在提示中列出所需的响应来限制 LLM 的响应</li>
<li>尝试不同的提示，看看哪种最适合您！</li>
</ol>
<p>继续使用这些新发现的技能开始工程提示，并记住，如果一开始没有成功，请再次尝试（提示的不同变体）！</p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-如何利用ChatGPT赚钱？" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h5 class="article-title" itemprop="name">
      <a href="/2023/07/04/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8ChatGPT%E8%B5%9A%E9%92%B1%EF%BC%9F/">如何利用ChatGPT赚钱？</a>
    </h5>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2023-07-04T15:26:48.000Z" itemprop="datePublished">
  2023-07-04
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      <p>您是否正在寻找无需付出太多努力即可产生被动收入的方法？由于人工智能和聊天机器人的进步，现在可以使用这些技术赚钱。在这篇博文中，我们将探讨非技术人员通过 ChatGPT 产生被动收入的一些最有效的方法。</p>
<p>ChatGPT 被誉为世界上最智能的生成人工智能，它正在改变在线赚钱的游戏规则。有了这个革命性的免费工具，您无需任何技能，无需资金，每天即可赚取 1000 美元或更多。</p>
<p>这是一个令人兴奋的人工智能新时代，现在是参与并利用这个机会的最佳时机。人们使用 ChatGPT 来观看 Youtube、写博客、自由职业以及许多其他赚钱方式。因此，让我们深入了解如何使用 ChatGPT 赚钱并产生各种被动收入。</p>
<p>可是等等！我们有一些您不想错过的东西：了解更多信息的绝佳机会。加入我们，踏上一段令人难以置信的知识和成长之旅。我们呼吁所有数据科学和人工智能爱好者参加2023 年 DataHack 峰会，该峰会将于 8 月 2 日至 5 日在班加罗尔的 NIMHANS 会议中心举行。通过实践学习、行业见解和交流机会体验激动人心的活动。不要错过这个令人难以置信的数据驱动思想的聚会！</p>
<p>目录<br>如何通过 ChatGPT 赚钱<br>使用 ChatGPT 获取一些商业创意<br>使用 ChatGPT 进行自由职业<br>使用 ChatGPT 写博客<br>内容创作<br>关键词研究和SEO优化<br>观众参与度<br>使用 ChatGPT 进行电子邮件联盟营销<br>将 ChatGPT 用于 Youtube 频道<br>使用 ChatGPT 编写电子书并自行出版<br>结论<br>如何通过 ChatGPT 赚钱<br>您可以通过多种方式使用 ChatGPT 赚钱。即使您对人工智能一无所知，请继续阅读，发现 6 种赚钱方法。</p>
<p>从 ChatGPT 获取商业创意<br>自由职业者<br>写博客<br>电子邮件营销<br>使用 ChatGPT 创建视频<br>撰写电子书并自行出版<br>让我们深入研究一下</p>
<p>使用 ChatGPT 获取一些商业创意<br>ChatGPT 是一款人工智能驱动的工具，可以帮助您产生被动收入。然而，为了最大限度地发挥其潜力，有效地利用它至关重要。</p>
<p>成为全栈数据科学家<br>转变为专家并对数据科学世界产生重大影响。<br>如果您不熟悉它的工作原理，没问题！只需询问适合您独特喜好的定制副业想法即可。ChatGPT 将通过了解您的兴趣、才能和障碍来发挥其魔力，然后生成符合您期望的定制业务概念。准备好开始不费吹灰之力就能赚到钱了！”</p>
<p>让我们向 ChatGPT 询问一位拥有数字营销和销售经验的数据分析师的一些商业想法。</p>
<p>使用 chatgpt 为自己创造业务<br>收到这些量身定制的想法后，您可以与 ChatGPT 进一步讨论，以概念化创业计划、考虑重要因素等。或者，您可以首先声明“为……生成一个新的商业想法”，并允许 ChatGPT 提供一些出色的建议。</p>
<p>使用chatgpt生成商业计划<br>通过充分利用 ChatGPT，您可以释放大量创收机会。</p>
<p>使用 ChatGPT 进行自由职业<br>使用 ChatGPT 将您的自由职业游戏提升到一个新的水平！这种最先进的人工智能工具使专业人士能够赚取额外收入并制作出令客户惊叹的高质量内容。公司甚至为那些利用这项技术创造出经过精心研究的精美作品的人提供奖励。</p>
<p>您可以使用 ChatGPT 提供的一些自由职业服务包括：</p>
<p>使用 ChatGPT 编写博客或网站内容<br>使用 CHATGPT 翻译任何语言<br>ChatGPT 的电子邮件写作服务<br>使用 ChatGPT 撰写标题和号召性用语<br>使用 ChatGPT 为 Youtube 视频编写脚本<br>为帖子或营销编写社交媒体内容<br>使用 ChatGPT 写一个短篇故事<br>使用 ChatGPT 进行主题标签研究<br>使用 ChatGPT 写博客<br>您可以通过多种方式利用 ChatGPT 的优势：</p>
<p>内容创作<br>这个人工智能驱动的工具可以帮助博主生成想法、大纲，甚至完成博客文章的草稿。当您感到陷入困境时，它非常适合。借助 ChatGPT，您可以节省数小时的研究时间，并在几秒钟内访问相关信息、统计数据和事实。准备好使用 ChatGPT 将您的博客游戏提升到新的水平。</p>
<p>使用 chatGPT 获取内容创意和大纲<br>编辑和校对<br>ChatGPT 被证明是博客作者的宝贵资产，它可以提供编辑、校对方面的帮助，并通过拼写、语法和理解方面的建议和更正来增强博客文章的整体可读性，从而帮助减少错误并确保清晰度。</p>
<p>关键词研究和SEO优化<br>搜索引擎优化 (SEO) 是博客的一个重要方面，ChatGPT 可以帮助您针对搜索引擎优化博客文章。它可以建议您的博客文章中包含的关键字，提供有关如何构建内容以获得最大可见度的指导，并提供有关如何提高整体在线形象的提示。</p>
<p>使用 ChatGPT 进行关键字研究和 SEO<br>单击此处了解有关 ChatGPT 如何帮助 Seo 优化的更多信息</p>
<p>观众参与度<br>ChatGPT 可以通过提供对话开始、回答常见问题和解决读者的疑虑来帮助博主与受众互动。这使得博主能够与受众进行更深层次的联系并建立忠实的追随者。</p>
<p>通过利用 ChatGPT 的功能，博主可以持续创建高质量的内容，吸引目标受众，提高整体在线形象并产生被动收入。</p>
<p>使用 ChatGPT 进行电子邮件联盟营销<br>使用 ChatGPT 赚钱的最简单方法之一是通过电子邮件联属营销。该聊天机器人拥有出色的写作技巧，可以起草令人信服的电子邮件，激励用户点击链接并进行购买或订阅服务。</p>
<p>要启动电子邮件联属营销活动，请选择一个联属计划，例如 Amazon、Shopify、ConvertKit 等。选择联属计划后，请创建一个电子邮件列表，针对对您所推广的产品或服务感兴趣的潜在客户。要构建此电子邮件列表，您可以使用铅磁铁或鼓励使用其他方法进行电子邮件注册。</p>
<p>在 ChatGPT 的帮助下，您可以制作引人入胜的电子邮件，不仅让用户了解产品的优点，还可以激励他们点击您的链接并进行购买。</p>
<p>使用 ChatGPT 进行电子邮件营销<br>使用 ChatGPT 进行联盟营销<br>通过电子邮件联属网络营销，您可以为通过推荐链接进行的每笔销售赚取佣金 - 所有这些都只需您付出最少的努力。那为什么还要等呢？今天就让 ChatGPT 帮助您启动可盈利的电子邮件活动！</p>
<p>将 ChatGPT 用于 Youtube 频道<br>借助 ChatGPT，您可以就您选择的类别中的视频想法进行集体讨论 - 如果您感到困惑，ChatGPT 甚至可以为您编写脚本。</p>
<p>让我们向 ChatGPT 询问一些有关时尚视频博主的 Youtube 视频创意。</p>
<p>使用 ChatGPT 获取 Youtube 视频创意。<br>现在，为您的 YouTube 视频生成脚本。</p>
<p>使用 ChatGPT 为您的 Youtube 频道或视频编写脚本<br>一旦您有了脚本，就可以使用Pictory.ai或invideo.io轻松将其转换为具有专业外观的视频。这些人工智能驱动的平台可以快速将您的文本转换为可在 YouTube 上发布的带旁白的视频。谁知道呢？凭借一些营销头脑，您可以开始兼职赚钱！</p>
<p>那为什么还要等呢？今天就让 ChatGPT 帮助您发现新的、令人兴奋的内容创意，并将您的 YouTube 频道提升到一个新的水平！</p>
<p>使用 ChatGPT 编写电子书并自行出版<br>您是否对写作充满热情，但很难想出新鲜和创新的想法？嗯，这就是 ChatGPT 的用武之地！据路透社最近报道，由于 ChatGPT 的推出，人工智能编写的电子书在亚马逊上出现了令人难以置信的增长。</p>
<p>从充满冒险故事的儿童读物到激励读者实现梦想的励志讲座，甚至是将读者带入新世界的惊心动魄的科幻小说 - 在 ChatGPT 的指导下，您可以实现无限的成就。</p>
<p>最好的部分是什么？您不需要成为文学天才才能在电子书市场上掀起波澜。借助 Kindle Direct Publishing，将您的图书发布到热切的读者手中从未如此简单。此外，使用 ChatGPT 编写电子书意味着您将节省时间和精力，让您能够更加专注于营销和推广您的工作。</p>
<p>因此，无论您是一位想要尝试新事物的经验丰富的作家，还是一位一直想出版自己的书的新手，通过 ChatGPT 自行出版都是赚取额外现金的合法且令人兴奋的方式。</p>
<p>结论<br>如果您正在寻找一种无需付出太多努力就能赚钱的方法，那么 ChatGPT 就是您的最佳选择。这种人工智能驱动的工具正在改变在线赚钱的游戏规则。借助 ChatGPT，您只需很少的技能且无需资金即可产生被动收入。</p>
<p>在这篇博文中，我们探讨了非技术人员使用 ChatGPT 赚钱的一些最有效方法。从获得商业创意到自由职业、博客、电子邮件营销、制作视频和编写电子书，使用这个革命性的工具有无限的赚钱可能性。</p>
<p>那为什么还要等呢？立即开始使用 ChatGPT，发现新的、令人兴奋的方式来产生被动收入。凭借其能力，可能性是无限的！</p>
<p>要了解有关生成模型开发和实践经验的更多信息，请加入我们在2023 年 DataHack 峰会上举办的“使用生成模型进行自然语言处理”研讨会。参加 2023 年 DataHack 峰会将改变您的游戏规则。这些研讨会旨在提供巨大的价值，为您提供实用技能和现实知识。凭借实践经验，您将有信心正面应对数据挑战。不要错过这个宝贵的机会，可以增强您的专业知识、与行业领导者建立联系并释放新的职业机会。立即注册参加 2023 年 DataHack 峰会！</p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-什么是Dreambooth？" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h5 class="article-title" itemprop="name">
      <a href="/2023/07/04/%E4%BB%80%E4%B9%88%E6%98%AFDreambooth%EF%BC%9F/">什么是Dreambooth？</a>
    </h5>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2023-07-04T13:26:35.000Z" itemprop="datePublished">
  2023-07-04
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      <p><a target="_blank" rel="noopener" href="https://dreambooth.github.io/">Dreambooth</a>由 Google 研究团队于 2022 年发布，是一种通过向模型注入自定义主题来微调扩散模型（如Stable Diffusion）的技术。</p>
<p>为什么叫Dreambooth？据谷歌研究团队称，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">It’s like a photo booth, but once the subject is captured, it can be synthesized wherever your dreams take you.</span><br></pre></td></tr></table></figure>

<p>DreamBooth 算法对 Imagen 模型进行了微调，从而实现了将现实物体在图像中真实还原的功能，通过少量实体物品图像的 fine-turning，使得原有的 SD 模型能对图像实体记忆保真，识别文本中该实体在原图像中的主体特征甚至主题风格，是一种新的文本到图像“个性化”（可适应用户特定的图像生成需求）扩散模型。</p>
<img src="/2023/07/04/%E4%BB%80%E4%B9%88%E6%98%AFDreambooth%EF%BC%9F/stable-diffusion-quick-kit-series-model-fine-tuning-with-dreambooth-optimization-practices-on-sagemaker2.png" class="" title="img">

<p>听起来很棒！但它的效果如何？下面是研究文章中的一个例子。仅使用特定狗（我们称之为<strong>Devora</strong>）的 3 张图像作为输入，dreamboothed 模型就可以在不同的环境中生成 Devora 的图像。</p>
<img src="/2023/07/04/%E4%BB%80%E4%B9%88%E6%98%AFDreambooth%EF%BC%9F/image-13.png" class="" title="dreambooth 研究文章中的 dreambooth 示例">

<p>只需 3 个训练图像，Dreambooth 即可将自定义主题无缝注入扩散模型。</p>
<h3 id="Dreambooth-如何运作？"><a href="#Dreambooth-如何运作？" class="headerlink" title="Dreambooth 如何运作？"></a>Dreambooth 如何运作？</h3><p>Dreambooth 是对整个神经网络所有层权重进行调整，会将输入的图像训练进 Stable Diffusion 模型，它的本质是先复制了源模型，在源模型的基础上做了微调（fine tunning）并独立形成了一个新模型，在它的基本上可以做任何事情。缺点是，训练它需要大量 VRAM, 目前经过调优后可以在 16GB 显存下完成训练。</p>
<p>您可能会问，为什么不能简单地使用这些图像通过额外的步骤来训练模型？问题是，这样做会因<em>过度拟合</em>（因为数据集非常小）导致失败。</p>
<p>Dreambooth 通过以下方式解决了这些问题：</p>
<ol>
<li>对新主题使用一个<strong>罕见的单词（请注意，我为狗使用了一个罕见的名字****Devora</strong>），这样它一开始在模型中就没有太多意义。</li>
<li><strong>类的预先保留</strong>：为了保留<strong>类</strong>（上例中的狗）的含义，模型以注入主体（Devora）的方式进行微调，同时生成类（狗）的图像。保存下来。</li>
</ol>
<p>还有另一种类似的技术称为<a target="_blank" rel="noopener" href="https://textual-inversion.github.io/"><a target="_blank" rel="noopener" href="https://textual-inversion.github.io/"> textual inversion</a>. </a>。不同之处在于，Dreambooth 对整个模型进行了微调，而<a target="_blank" rel="noopener" href="https://textual-inversion.github.io/"> textual inversion</a>.则注入了一个新词，而不是重复使用生僻词，并且仅对模型的文本嵌入部分进行了微调。</p>
<h3 id="训练-Dreambooth-需要什么？"><a href="#训练-Dreambooth-需要什么？" class="headerlink" title="训练 Dreambooth 需要什么？"></a>训练 Dreambooth 需要什么？</h3><p>你需要三样东西</p>
<ol>
<li>一些自定义图像</li>
<li>唯一标识符</li>
<li>一个类名class</li>
</ol>
<p>在上面的例子中。唯一标识符是<strong>Devora</strong>，class名称是<strong>狗</strong>。</p>
<p>然后你需要构建你的<strong>实例提示</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a photo of [unique identifier] [class name]</span><br></pre></td></tr></table></figure>

<p>还有<strong>class提示</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a photo of [class name]</span><br></pre></td></tr></table></figure>

<p>在上面的例子中，<strong>实例提示符</strong>是</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a photo of Devora dog</span><br></pre></td></tr></table></figure>

<p>由于 Devora 是一只狗，所以<strong>class提示</strong>是</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a photo of a dog</span><br></pre></td></tr></table></figure>

<h3 id="获取训练图像"><a href="#获取训练图像" class="headerlink" title="获取训练图像"></a>获取训练图像</h3><p>为您的自定义主题拍摄 3-10 张照片。照片应该从不同的角度拍摄。</p>
<p>拍摄对象还应该处于多种背景中，以便模型可以将拍摄对象与背景区分开来。</p>
<p>我将在教程中使用这个玩具。</p>
<img src="/2023/07/04/%E4%BB%80%E4%B9%88%E6%98%AFDreambooth%EF%BC%9F/0E5AFC83-B759-4FE9-8E16-A60774E1DEDF_1_105_c.jpeg" class="" title="img">

<h3 id="调整图像大小"><a href="#调整图像大小" class="headerlink" title="调整图像大小"></a>调整图像大小</h3><p>为了在训练中使用图像，您首先需要将它们的大小调整为 512×512 像素，以便使用 v1 模型进行训练。</p>
<p><a target="_blank" rel="noopener" href="https://www.birme.net/?target_width=512&target_height=512">BIRME</a>是一个调整图像大小的便捷网站。</p>
<ol>
<li>将您的图像拖放到 BIRME 页面。</li>
<li>调整每张图像的画布，使其充分显示主题。</li>
<li>确保宽度和高度均为 512 像素。</li>
<li>按<strong>“</strong>SAVE FILES** ”**将调整大小的图像保存到您的计算机。</li>
</ol>
<img src="/2023/07/04/%E4%BB%80%E4%B9%88%E6%98%AFDreambooth%EF%BC%9F/image-14.png" class="" title="img">

<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>目前业界对 DreamBooth 做 fine tuning 主要为两种方式，一是在 Stable Diffusion WebUI 可视话界面进行模型的选择，训练图片的上载及本地化的训练；二是在第三方 IDE 平台如 colab notebook 上以脚本交互式开发的方式进行训练。</p>
<p>第一种方式只能在部署 Stable Diffusion WebUI 应用的单一服务器或主机上训练，无法与企业及客户的后台平台及业务集成；而第二种方式侧重于算法工程师个人在开发测试阶段进行模型实验探索，无法实现生产化工程化的部署。此外，以上两种方式训练 dreambooth，还需要关注高性能算力机资源的成本（尤其对模型效果要求较高的场景，需要多达 50 张以上的 class images，显存容易 OOM），基础模型和 fine tuning 后模型的存储和管理，训练超参的管理，统一的日志监控，训练加速，依赖 lib 编译打包等具体实施落地层面的一系列困难和挑战。</p>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time_start = time.time()</span><br><span class="line"><span class="comment">#@title DreamBooth</span></span><br><span class="line">HUGGINGFACE_TOKEN = <span class="string">&quot;&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#@markdown Name/Path of the initial model. (Find model name [here](https://huggingface.co/models))</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;runwayml/stable-diffusion-v1-5&quot;</span> <span class="comment">#@param &#123;type:&quot;string&quot;&#125;</span></span><br><span class="line">BRANCH = <span class="string">&quot;fp16&quot;</span> <span class="comment">#@param &#123;type:&quot;string&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#@markdown Enter instance prompt and class prompt.\</span></span><br><span class="line"><span class="comment">#@markdown Example 1: photo of zwx person, photo of a person\</span></span><br><span class="line"><span class="comment">#@markdown Example 2: photo of zwx toy, photo of a toy</span></span><br><span class="line">instance_prompt = <span class="string">&quot;photo of zwx toy&quot;</span> <span class="comment">#@param &#123;type:&quot;string&quot;&#125;</span></span><br><span class="line">class_prompt =  <span class="string">&quot;photo of a toy&quot;</span> <span class="comment">#@param &#123;type:&quot;string&quot;&#125;</span></span><br><span class="line">training_steps = <span class="number">800</span> <span class="comment">#@param &#123;type:&quot;integer&quot;&#125;</span></span><br><span class="line">learning_rate = <span class="number">1e-6</span> <span class="comment">#@param &#123;type:&quot;number&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#@markdown  Convert to fp16? (takes half the space (2GB)).</span></span><br><span class="line">fp16 = <span class="literal">True</span> <span class="comment">#@param &#123;type: &quot;boolean&quot;&#125;</span></span><br><span class="line"><span class="comment">#@markdown  Compile xformers (Try only if you see xformers error. Will take 1 more hour).</span></span><br><span class="line">complie_xformers = <span class="literal">False</span> <span class="comment">#@param &#123;type: &quot;boolean&quot;&#125;</span></span><br><span class="line"></span><br><span class="line">save_to_gdrive = <span class="literal">True</span></span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line"><span class="keyword">if</span> save_to_gdrive:</span><br><span class="line">  drive.mount(<span class="string">&#x27;/content/drive&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#@markdown Clear log after run?</span></span><br><span class="line">CLEAR_LOG = <span class="literal">False</span> <span class="comment">#@param &#123;type:&quot;boolean&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">OUTPUT_DIR = <span class="string">&quot;stable_diffusion_weights/output&quot;</span> </span><br><span class="line">OUTPUT_DIR = <span class="string">&quot;/content/&quot;</span> + OUTPUT_DIR</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check type of GPU and VRAM available.</span></span><br><span class="line">!nvidia-smi --query-gpu=name,memory.total,memory.free --<span class="built_in">format</span>=csv,noheader</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;[*] Weights will be saved at <span class="subst">&#123;OUTPUT_DIR&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">!mkdir -p $OUTPUT_DIR</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># You can also add multiple concepts here. Try tweaking `--max_train_steps` accordingly.</span></span><br><span class="line"></span><br><span class="line">concepts_list = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;instance_prompt&quot;</span>:      instance_prompt,</span><br><span class="line">        <span class="string">&quot;class_prompt&quot;</span>:         class_prompt,</span><br><span class="line">        <span class="string">&quot;instance_data_dir&quot;</span>:    <span class="string">&quot;/content/data/instance&quot;</span>,</span><br><span class="line">        <span class="string">&quot;class_data_dir&quot;</span>:       <span class="string">&quot;/content/data/class&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># `class_data_dir` contains regularization images</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> concepts_list:</span><br><span class="line">    os.makedirs(c[<span class="string">&quot;instance_data_dir&quot;</span>], exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;concepts_list.json&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(concepts_list, f, indent=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> files</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> concepts_list:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Uploading instance images for `<span class="subst">&#123;c[<span class="string">&#x27;instance_prompt&#x27;</span>]&#125;</span>`&quot;</span>)</span><br><span class="line">    uploaded = files.upload()</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> uploaded.keys():</span><br><span class="line">        dst_path = os.path.join(c[<span class="string">&#x27;instance_data_dir&#x27;</span>], filename)</span><br><span class="line">        shutil.move(filename, dst_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clear</span>():</span><br><span class="line">    <span class="keyword">from</span> IPython.display <span class="keyword">import</span> clear_output; <span class="keyword">return</span> clear_output()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># huggingface token</span></span><br><span class="line">!mkdir -p ~/.huggingface</span><br><span class="line">!echo -n <span class="string">&quot;&#123;HUGGINGFACE_TOKEN&#125;&quot;</span> &gt; ~/.huggingface/token</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># install repos</span></span><br><span class="line">!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py</span><br><span class="line">!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py</span><br><span class="line"><span class="comment">#%pip install torch==2.0.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</span></span><br><span class="line">%pip install -qq git+https://github.com/ShivamShrirao/diffusers</span><br><span class="line">%pip install -q -U --pre triton</span><br><span class="line">%pip install -q accelerate==<span class="number">0.19</span><span class="number">.0</span> transformers ftfy bitsandbytes==<span class="number">0.35</span><span class="number">.0</span> gradio natsort safetensors xformers</span><br><span class="line"><span class="comment"># install xformer wheel</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Install xformers&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> complie_xformers:</span><br><span class="line">  %pip install git+https://github.com/facebookresearch/xformers@4c06c79<span class="comment">#egg=xformers</span></span><br><span class="line"><span class="comment">#else:</span></span><br><span class="line"><span class="comment">#  %pip install  --no-deps -q https://github.com/brian6091/xformers-wheels/releases/download/0.0.15.dev0%2B4c06c79/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl</span></span><br><span class="line"><span class="comment">#%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/4c06c79_various6/xformers-0.0.15.dev0_4c06c79.d20221201-cp38-cp38-linux_x86_64.whl</span></span><br><span class="line"><span class="comment">#%pip install -q https://github.com/ShivamShrirao/xformers-wheels/releases/download/4c06c79/xformers-0.0.15.dev0+4c06c79.d20221201-cp38-cp38-linux_x86_64.whl</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############## Edit this section to customize parameters</span></span><br><span class="line">!python3 train_dreambooth.py \</span><br><span class="line">  --pretrained_model_name_or_path=$MODEL_NAME \</span><br><span class="line">  --pretrained_vae_name_or_path=<span class="string">&quot;stabilityai/sd-vae-ft-mse&quot;</span> \</span><br><span class="line">  --output_dir=$OUTPUT_DIR \</span><br><span class="line">  --revision=$BRANCH \</span><br><span class="line">  --with_prior_preservation --prior_loss_weight=<span class="number">1.0</span> \</span><br><span class="line">  --seed=<span class="number">1337</span> \</span><br><span class="line">  --resolution=<span class="number">512</span> \</span><br><span class="line">  --train_batch_size=<span class="number">1</span> \</span><br><span class="line">  --train_text_encoder \</span><br><span class="line">  --mixed_precision=<span class="string">&quot;fp16&quot;</span> \</span><br><span class="line">  --use_8bit_adam \</span><br><span class="line">  --gradient_accumulation_steps=<span class="number">1</span> \</span><br><span class="line">  --learning_rate=$learning_rate \</span><br><span class="line">  --lr_scheduler=<span class="string">&quot;constant&quot;</span> \</span><br><span class="line">  --lr_warmup_steps=<span class="number">0</span> \</span><br><span class="line">  --num_class_images=<span class="number">50</span> \</span><br><span class="line">  --sample_batch_size=<span class="number">4</span> \</span><br><span class="line">  --max_train_steps=$training_steps \</span><br><span class="line">  --save_interval=<span class="number">10000</span> \</span><br><span class="line">  --save_sample_prompt=<span class="string">&quot;$instance_prompt&quot;</span> \</span><br><span class="line">  --concepts_list=<span class="string">&quot;concepts_list.json&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reduce the `--save_interval` to lower than `--max_train_steps` to save weights from intermediate steps.</span></span><br><span class="line"><span class="comment"># `--save_sample_prompt` can be same as `--instance_prompt` to generate intermediate samples (saved along with weights in samples directory).</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> natsort <span class="keyword">import</span> natsorted</span><br><span class="line"><span class="keyword">from</span> glob <span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">weightdirs = natsorted(glob(OUTPUT_DIR + os.sep + <span class="string">&quot;*&quot;</span>))</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(weightdirs) == <span class="number">0</span>:</span><br><span class="line">  <span class="keyword">raise</span> KeyboardInterrupt(<span class="string">&quot;No training weights directory found&quot;</span>)</span><br><span class="line">WEIGHTS_DIR = weightdirs[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ckpt_path = WEIGHTS_DIR + <span class="string">&quot;/model.ckpt&quot;</span></span><br><span class="line"></span><br><span class="line">half_arg = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> fp16:</span><br><span class="line">    half_arg = <span class="string">&quot;--half&quot;</span></span><br><span class="line">!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;[*] Converted ckpt saved at <span class="subst">&#123;ckpt_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> CLEAR_LOG:</span><br><span class="line">  clear()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;[*] WEIGHTS_DIR=<span class="subst">&#123;WEIGHTS_DIR&#125;</span>&quot;</span>)</span><br><span class="line">minutes = (time.time()-time_start)/<span class="number">60</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Dreambooth completed successfully. It took %1.1f minutes.&quot;</span>%minutes)</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"></span><br><span class="line">weights_folder = OUTPUT_DIR</span><br><span class="line">folders = <span class="built_in">sorted</span>([f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(weights_folder) <span class="keyword">if</span> f != <span class="string">&quot;0&quot;</span>], key=<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x))</span><br><span class="line"></span><br><span class="line">row = <span class="built_in">len</span>(folders)</span><br><span class="line">col = <span class="built_in">len</span>(os.listdir(os.path.join(weights_folder, folders[<span class="number">0</span>], <span class="string">&quot;samples&quot;</span>)))</span><br><span class="line">scale = <span class="number">4</span></span><br><span class="line">fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw=&#123;<span class="string">&#x27;hspace&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;wspace&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, folder <span class="keyword">in</span> <span class="built_in">enumerate</span>(folders):</span><br><span class="line">    folder_path = os.path.join(weights_folder, folder)</span><br><span class="line">    image_folder = os.path.join(folder_path, <span class="string">&quot;samples&quot;</span>)</span><br><span class="line">    images = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(image_folder)]</span><br><span class="line">    <span class="keyword">for</span> j, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">        <span class="keyword">if</span> row == <span class="number">1</span>:</span><br><span class="line">            currAxes = axes[j]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            currAxes = axes[i, j]</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            currAxes.set_title(<span class="string">f&quot;Image <span class="subst">&#123;j&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">            currAxes.text(-<span class="number">0.1</span>, <span class="number">0.5</span>, folder, rotation=<span class="number">0</span>, va=<span class="string">&#x27;center&#x27;</span>, ha=<span class="string">&#x27;center&#x27;</span>, transform=currAxes.transAxes)</span><br><span class="line">        image_path = os.path.join(image_folder, image)</span><br><span class="line">        img = mpimg.imread(image_path)</span><br><span class="line">        currAxes.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">        currAxes.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">&#x27;grid.png&#x27;</span>, dpi=<span class="number">72</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> save_to_gdrive:</span><br><span class="line">  <span class="keyword">import</span> os.path</span><br><span class="line">  gPath = <span class="string">&quot;/content/drive/MyDrive/Dreambooth_model&quot;</span></span><br><span class="line">  !mkdir -p $gPath</span><br><span class="line">  filename = <span class="string">&#x27;model.ckpt&#x27;</span></span><br><span class="line">  i = <span class="number">1</span></span><br><span class="line">  ckpt_gpath = gPath + <span class="string">&#x27;/&#x27;</span> + filename</span><br><span class="line">  <span class="keyword">while</span> os.path.isfile(ckpt_gpath):</span><br><span class="line">    filename = <span class="string">&#x27;model%d.ckpt&#x27;</span>%i</span><br><span class="line">    ckpt_gpath = gPath + <span class="string">&#x27;/&#x27;</span> + filename</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">  ckpt_gpath = gPath + <span class="string">&#x27;/&#x27;</span> + filename</span><br><span class="line">  !cp $ckpt_path $ckpt_gpath</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;Model saved to %s&#x27;</span>%ckpt_gpath)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>完成训练大约需要30分钟。完成后模型可以放入AUTOMATIC1111 GUI ，就可以用新模型生成的一些示例图像。</p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-GPU虚拟化" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h5 class="article-title" itemprop="name">
      <a href="/2023/06/27/GPU%E8%99%9A%E6%8B%9F%E5%8C%96/">GPU虚拟化</a>
    </h5>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2023-06-27T11:53:18.000Z" itemprop="datePublished">
  2023-06-27
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      <p>GPU 资源池化技术从初期的简单虚拟化，到资源池化，经历了四个技术演进阶段。</p>
<p><strong>简单虚拟化</strong></p>
<p>将物理 GPU 按照 2 的 N 次方，切分成多个固定大小的 vGPU（VirtualGPU，虚拟 GPU），每个 vGPU 的算力和显存相等。实践证明，不同的 AI 模型对于算力、显存资源的需求是不同的。所以，这样的切分方式，并不能满足 AI 模型多样化的需求。</p>
<p><strong>任意虚拟化</strong></p>
<p>将物理 GPU 按照算力和显存两个维度，自定义切分，获得满足 AI 应用个性化需求的 vGPU。</p>
<p><strong>远程调用</strong></p>
<p>AI 应用与物理 GPU 服务器分离部署，允许通过高性能网络远程调用 GPU资源。这样可以实现 AI 应用与物理 GPU 资源剥离，AI 应用可以部署在私有云的任</p>
<p>意位置，只需要网络可达，即可调用 GPU 资源。</p>
<p><strong>资源池化</strong></p>
<p>形成 GPU 资源池后，需要统一的管理面来实现管理、监控、资源调度和资源回收等功能。同时，也需要提供北向 API，与数据中心级的资源调度平台对</p>
<p>接，让用户在单一界面，就可以调度包括 vGPU 在内的数据中心内的各类资源。</p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-如何使用-ChatGPT-和-LangChain-框架构建自己的QA应用" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h5 class="article-title" itemprop="name">
      <a href="/2023/06/26/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-ChatGPT-%E5%92%8C-LangChain-%E6%A1%86%E6%9E%B6%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84QA%E5%BA%94%E7%94%A8/">如何使用 ChatGPT 和 LangChain 框架构建自己的QA应用</a>
    </h5>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2023-06-25T22:50:32.000Z" itemprop="datePublished">
  2023-06-26
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      <p>大型语言模型 (LLM) 正在成为一种变革性技术，使开发人员能够构建他们以前无法构建的应用程序。但是单独使用这些 LLM 往往不足以创建一个真正强大的应用程序——当您可以将它们与其他计算或知识来源相结合时，真正的力量就来了。</p>
<p>LLM 本质上是非常通用的，这意味着虽然它们可以有效地执行许多通用的任务，比如回答如何制作一道美味的红烧肉。但它们通常不能直接为特定领域的问题或任务提供具体答案。</p>
<p><strong>这里就提出了一个问题：如何基于ChatGPT为自己的业务赋能。</strong></p>
<p>虽然官方提供了微调服务，但是由于缺乏最佳实践作为参考，加上费用不小，对于很多没有专门的算法人员的企业来说，显然微调不是一个好选择。</p>
<p>幸运的是，LangChain出现了，它是包含一个称为数据增强生成的功能，它允许您提供一些上下文数据来增强 LLM 的知识；</p>
<p>今天就给大家介绍下如何基于自己文本资料，构建基于文档的问答Demo。</p>
<p>代码的结构可以分为3个主要部分：</p>
<ol>
<li><p>1.加载自己的txt文件(里面是自己业务领域的东西)</p>
</li>
<li><p>2.创建embedding和向量化</p>
</li>
<li><p>3.查询txt</p>
</li>
</ol>
<p>现在，让我们深入了解这些步骤中的每一个！</p>
<p>运行前提条件：</p>
<p>需要有个OpenAI api_key用于程序跟ChatGPT做身份验证，这个需要去OpenAI 官方注册，如果你不会搞，可以留言说明。</p>
<p>python安装依赖：我用的python 3.11.1</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install langchain llama_index openai chromadb</span><br></pre></td></tr></table></figure>

<p>然后我们需要在终端中设置环境变量，设置open api。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export OPENAI_API_KEY=&quot;...&quot;</span><br></pre></td></tr></table></figure>

<p>或者，您可以从 Jupyter notebook（或 Python 脚本）中执行此操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import osos.environ[&quot;OPENAI_API_KEY&quot;] = &quot;...&quot;</span><br></pre></td></tr></table></figure>

<p>首先准备一个content.txt文档，文件里存入一些数据，内容摘录：</p>
<img src="/2023/06/26/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-ChatGPT-%E5%92%8C-LangChain-%E6%A1%86%E6%9E%B6%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84QA%E5%BA%94%E7%94%A8/640.png" class="" title="图片">

<p>现在创建一个程序来完成问答：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> TextLoader</span><br><span class="line"><span class="comment"># 加载放了QA的txt文件</span></span><br><span class="line">loader = TextLoader(<span class="string">&quot;content.txt&quot;</span>)</span><br><span class="line">documents = loader.load()</span><br><span class="line"><span class="comment"># 把大段文字切成小块</span></span><br><span class="line">text_splitter = CharacterTextSplitter(chunk_size=<span class="number">200</span>, chunk_overlap=<span class="number">0</span>)</span><br><span class="line">texts = text_splitter.split_documents(documents)</span><br><span class="line"><span class="comment"># 创建embeddings</span></span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line">docsearch = Chroma.from_documents(texts, embeddings)</span><br><span class="line"><span class="comment"># 通过这个OpenAIEmbedding api给每个小文档计算embedding，存到doc_search</span></span><br><span class="line"><span class="comment"># 根据查询输入找到相似度最高的块作为上下文</span></span><br><span class="line">qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=<span class="string">&quot;stuff&quot;</span>, retriever=docsearch.as_retriever())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">query</span>(<span class="params">q</span>):</span><br><span class="line">     <span class="built_in">print</span>(<span class="string">f&quot;Query: <span class="subst">&#123;q&#125;</span>&quot;</span>)</span><br><span class="line">     <span class="built_in">print</span>(<span class="string">f&quot;Answer: <span class="subst">&#123;qa.run(q)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">     <span class="built_in">print</span>(query(<span class="string">&quot;如何开会&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>我们看下结果, 返回结果就是我原始文档中数据，很强大有没有!而且代码也很简单。</p>
<img src="/2023/06/26/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-ChatGPT-%E5%92%8C-LangChain-%E6%A1%86%E6%9E%B6%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84QA%E5%BA%94%E7%94%A8/640-1687733479465-1.png" class="" title="图片">

<p>借助这个小案例，其实也就是抛砖引玉，这里关键就是引入了LangChain这个框架，把ChatGPT和LangChain结合那就是如虎填翼。有了这样一个基础，你想想只要能文本化的东西都能创建这样一个知识提取的应用，结合特定业务那就有非常多的应用空间。</p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-LoRA是什么？" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h5 class="article-title" itemprop="name">
      <a href="/2023/06/26/LoRA%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/">LoRA是什么？</a>
    </h5>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2023-06-25T22:48:58.000Z" itemprop="datePublished">
  2023-06-26
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      <p><strong>1. LoRA介绍</strong></p>
<p>LoRA（ Low-rank Adaptation）是微软研究员引入的一项新技术，主要用于处理大模型微调的问题，本文主要介绍Lora如何微调Stable Diffusion。除此之外微调Stable Diffusion还有DreamBooth（DR）和Textual Inversion（TI）等训练技术。</p>
<p>LoRA有什么厉害之处？实际上LoRA在文件大小和训练能力之间提供了一个很好的平衡。DR虽然功能强大，但是生成的模型文件很大（2-7G）。TI生成的文件虽小（100k），但是训练效果不怎么好。</p>
<p>LoRA介于两者之间，模型（2-200M）文件大小可控，训练能力不错。玩过Stable Diffusion的人都知道，要试验各种模型，前提是你要有足够的磁盘空间，一般一个模型都是好几G的。下载那么大的模型，你的网络带宽也得非常OK（至少每秒几M），不然真的没耐心。所以这也是LoRA比较流行的原因之一吧。与TI相同，LoRA模型不能单独使用，必须与训练的基础模型配合一起使用。</p>
<p><strong>2. LoRA是如何工作的？</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">首先我们来看看Stable Diffusion的架构，主要由三部分组成：文本编码器，可将您的提示词转换为latent向量。一种扩散模型，它反复对 64x64 latent patch进行&quot;去噪&quot;。解码器，将最终的 64x64 latent patch转换为更高分辨率的 512x512 图像。它的一个处理过程就是下图所示，上面每一个组成部分都是一个模型，然后通过PIPLINE把几个模型串联起来，就可以达到生成图片的效果。而且每个部分实际上都是可以独立部署的。</span><br></pre></td></tr></table></figure>



<p>最近总是听到LoRA，LoRA，名字怪好听，就是难理解，什么低秩适应完全搞不懂，今天就来扒扒，看看它是怎么个低法。</p>
<p>原来LoRA对Stable Diffusion模型最关键的部分进行了微小修改：cross-attention layers，它是模型中图像和提示相交的部分-交叉注意层（U-Net 噪声预测器的 QKV 部分）。</p>
<img src="/2023/06/26/LoRA%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/640.png" class="" title="图片">



<p>研究人员发现，通过聚焦大模型的 Transformer 注意力块，使用 LoRA 进行的微调质量与全模型微调相当，同时速度更快且需要更少的计算。</p>
<p>Simo Ryu (<code>@cloneofsimo</code>) 是第一个提出适用于 Stable Diffusion 的 LoRA实现的人。如果想查看相关示例和许多其他有趣的讨论和见解。请一定要看看他们的GitHub 项目。</p>
<p>cross-attention 注意力交叉层的权重排列在矩阵中。矩阵是一堆按行和列排列的数字<br>就像在Excle里面一样。LoRA通过将其权重添加到这些矩阵来微调模型。</p>
<p>假设模型是包含1000行和2000列的矩阵。那模型需要存2,000,000 个数字 (1,000 x 2,000)。</p>
<p>LoRA将矩阵分解为：1,000×2 矩阵和 2×2,000 矩阵。那模型只需要存 6,000 个数字 (1,000 x 2 + 2 x 2,000)，少了333倍，这就是LoRA文件小得多的原因。</p>
<p>我们看下作者在github中的介绍：</p>
<img src="/2023/06/26/LoRA%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/640-1687733382169-1.png" class="" title="图片">



<p>意思就是说：完全微调过程慢，在质量和训练速度很难找到平衡，虽然也有像TI这样的方法，但是效果不理想。LoRA的出现解决了社区遇到的问题：就是模型太大，用户想要基于社区各种模型进行微调，因为模型太大而无法使用，LoRA尝试微调模型的残差，而不是整个模型：也就训练delta W代替W。而delta W进一步分解成A矩阵和B的转置矩阵相乘。然后微调A和B替代W，A和B比原始的W要小多。</p>
<img src="/2023/06/26/LoRA%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/640-1687733382169-2.jpeg" class="" title="图片">


<p>LoRA 将一个大矩阵分解为两个小的低阶矩阵，在这个例子中，矩阵的秩为2。它比原始维度低很多，所以被称之为低秩矩阵。</p>
<p>使用 LoRA 对插图数据集进行微调：W&#x3D;W0 + aΔW， a是合并比率。ΔW说就是上面说的矩阵A矩阵和B矩阵的转置乘积，gif是将 alpha从0缩放到1。将alpha设置为0与使用原始模型相同，将alpha设置为1与使用完全微调的模型相同，通过整个公式我们也就清楚了LoRA为什么要配合基础模型一起用，因为W0来自于基础模型（几个G），ΔW来自于自己训练的LoRA模型（小，百M），用a来控制两个模型的融合程度。</p>
<img src="/2023/06/26/LoRA%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/640-1687733382169-3.gif" class="" title="图片">




<p><strong>3. 在哪里可以找到LoRA模型？</strong>  </p>
<p>这里推荐3个：<br>第一个是civitai.com,江湖人称之为C站，模型很丰富，因为有些模型不合规，国内现在直接访问不了，需要魔法。<br>第二个是Hugging Face,模型不是很多，但是还有很多不错的模型可挑选。<br>第三个是炼丹阁：这是一家国内公司连夜去civitai搬运的，模型经过了筛选，具有一定的合规性，试过也可以。</p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-1-LoRA介绍" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h5 class="article-title" itemprop="name">
      <a href="/2023/06/26/1-LoRA%E4%BB%8B%E7%BB%8D/">1. LoRA介绍</a>
    </h5>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2023-06-25T22:48:21.000Z" itemprop="datePublished">
  2023-06-26
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      
    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-sd-webui-只能由一个用户同时使用吗？" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h5 class="article-title" itemprop="name">
      <a href="/2023/06/20/sd-webui-%E5%8F%AA%E8%83%BD%E7%94%B1%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7%E5%90%8C%E6%97%B6%E4%BD%BF%E7%94%A8%E5%90%97%EF%BC%9F/">sd-webui 只能由一个用户同时使用吗？</a>
    </h5>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2023-06-19T23:36:30.000Z" itemprop="datePublished">
  2023-06-20
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      <p>有人在AUTOMATIC1111问：<br>我在带有 NVIDIA Tesla T4 的 GPU 服务器上部署了一个 sd webui，并配置了一个远程服务，这意味着任何地方的任何人都可以通过 GPU 服务器的公共 IP 地址访问 sd webui url。</p>
<p>例如，Li 从纽约访问 webui url，而 James 从芝加哥访问 webui url</p>
<p>但是我发现如果李正在生成图像，同时，詹姆斯点击生成按钮，他必须等待李完成她的生成工作（webui 显示“等待，排队”）。真是令人费解，李在生成图像时GPU服务器几乎空闲，为什么詹姆斯不能立即开始生成？如果我希望 2 或 200 人可以同时从不同的地方开始生成图像，我该怎么办？</p>
<p>Q：如何配置为“启动多个 WebUI 实例，我是新手？</p>
<p>A: 如果启动多个WebUI，它们会默认挂载在不同的端口上，可以并行工作。 由于 Python 的性质，单实例并行是不可能的。</p>
<p>总结：在不同的 web 端口上启动 web 服务，并部署负载平衡以响应多用户生成的请求。</p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
      <div class="col-3">
        <article id="post-controlnet更新" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h5 class="article-title" itemprop="name">
      <a href="/2023/06/18/controlnet%E6%9B%B4%E6%96%B0/">controlnet更新</a>
    </h5>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2023-06-17T23:50:57.000Z" itemprop="datePublished">
  2023-06-18
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      <p>在你没注意的时候ControlNet又更新了几次？ ControlNet更新总整理!! - YouTube<br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=PTyWM15W7mg">https://www.youtube.com/watch?v=PTyWM15W7mg</a></p>
<p>Transcript:</p>
<p>（00：16） 大家好， 今天我们来更新一下信息 从上一篇tile模型更新后 ControlNet又用非常惊人的速度持续更新 今天我们来看看 到底又更新了些什么吧 在开始前说一下 我们拍这片的时候 Controlnet的版本是1.1.201版 那就开始吧 首先Controlnet最让人诟病的问题 就是模型跟预处理器非常的乱 现在的Controlnet预处理器 大概有40个以上 然后模型也有十几个 每一个选择都非常花时间 现在终于出现了非常方便的选择器 只需要在画面上 点选你要的内容 例如我选openpose 系统就会把openpose 能够对应的预处理器放上去 如果你有对应的模型 系统也会帮你把模型放好 非常的方便 </p>
<p>（01：19） 之后不用在预处理器之海迷航啦 接下来我们来说说 又增加了什么预处理器吧 第一个是Depth 他新增了一个leres++ 这个预处理器 对画面的细分度更高 可以针对每一个区域 做出更明确的分类 我们来看一下对照图 这是每一个预处理器 分别画出五张 从中间挑出三张比较好的结果 在我看来 细致度排名分别是这样子 什么意思呢 就是leres++ 对画面的还原度最高 不过主要还是看你的需求 再选择要使用的预处理器 接着我们看Tile Tile多了两个预处理器 过去有使用过tile应该会知道tile在放大动漫图像的时候会有颜色失真的问题 原本的颜色会跑掉很多还有一些报告指出某些部分会模糊通常是因为CFG不足导致 </p>
<p>（02：24） 所以目前tile针对这两个问题 做了对应的处理 经过调整 已经不需要提高CFG去控制Tile了 另外增加了两个预处理器 一个是tile_colorfix 他会针对颜色做补正 让颜色不会跑掉 另一个是tile_colorfix+sharp 这个是颜色补正加上锐利化 下方还有可以调整锐利度的滑块 这也是目前官方最推荐的预处理器 大家可以参考一下 目前在颜色修复上 我认为效果非常明显 但是要注意 colorfix会把原图的颜色锁死 是没有办法靠提词改变颜色的喔 再来是inpaint 在过去要使用inpaint模型的时候 通常我们会使用图生图的局部重绘 但是这样会有一个问题 我们得要上面涂一次屏蔽 下面ControlNet也图一次屏蔽 现在ControlNet不用这么麻烦了 </p>
<p>（03：27） 我们只需要在局部重绘的地方涂好屏蔽 下方ControlNet的部分 不需要放入任何东西 只需要选择局部重绘 ControlNet的启用打勾 直接按下生产就可以了 系统会自动把局部重绘的图像 送到ControlNet里面 就不用像过去的教学一样 上下都涂屏蔽了 而inpaint目前多了一个 inpaint_only预处理器 这个预处理器是用在 不使用webui的局部重绘功能时 如果你用inpaint_only预处理器 系统就不会重绘屏蔽以外的部分 最后是Reference 这是一个全新功能 他只有预处理器 不需要模型 Reference是一个概念简单 但是非常强大的功能 我们先来说一下原理 Reference的意思是参考 那他怎么参考的呢 其实就是将我们用来参考的图像 先送进SD的注意力层 等到我们的提词和参数进入的时候 做为参考 </p>
<p>（04：31） 得出相近的结果 目前Reference有三种 参考的方式有点不同 我们一样直接上对照图 Reference_only 读取的比较像是风格 Reference_adain 比较像是构图 最后是Reference_adain+attn 这是前面两个的结合 所以构图跟风格都会转移 这个功能有一个重点 他对参考图像的质量要求很高 如果你的图片是网页上面的照片 很容易产生质量不佳的状况 今天就介绍到这边（？ 等一下！！ 在视频快做完的时候 ControlNet又更新了4次 我们又有一个重大的更新 大家知道Adobe的Filefly 前阵子发布了 生成式填色的功能吧 不使用任何提词 就可以获得很棒的重绘结果 这个功能甚至可以轻松的向外绘制 前几天如果你问 SD能不能做一样的事 那答案是否定的 我们不使用任何提词 </p>
<p>（05：34） 就没有办法达成这个效果 而且结果并没有办法非常多样化 但就在前不久 ControlNet做到了 我们现在可以用SD 重现类似的成果 做法很简单 只要再文生图的地方使用inpaint 需要的只有高分辨率修复打勾 CFG官方建议小于5 接着打开ControlNet 模型选择局部重绘 下方的控制模式 改成ControlNet更重要 接着放上你想要填色的图片 这边要注意你的预处理器了 使用inpaint only 才不会改变屏蔽以外的图像 针对要填色的区域涂上屏蔽后 只要按下产生就可以了 如果你想要画面多做一些改变 只要加上少量的提 词 就能够获得很好的成果 那如果想要向外绘制呢 我们现在也可以用inpaint来达成了 只要把ControlNet的缩放模式 </p>
<p>（06：38） 改为调整大小并填充 接着调整你需要扩张的像素 按下一次产生 就会获得一张向外扩充的图片 接着再把这张图片 放入ControlNet中 把需要扩充的内容图上屏蔽 当然也可以再其他绘图软件中先做好 再放到SD里面 就不需要只是为了把图像扩张（口误） 而多执行一次 说不定你看到这部影片的时候 已经不需要这样做了 最后只要按下产生就完成了 今天真的就介绍到这边 各位看完这篇的时候 ControlNet可能又更新了好几次了 等过阵子 我们再来整理ControlNet又会了些什么吧 那就这样啦 下次见 掰</p>

    </div>
    <footer class="article-footer">
      
    </footer>
  </div>
  
  
</article>
      </div>
      
  </div>


  


        </div>
      
      
        <div class="d-flex justify-content-center pt-5">
          <a href="/archives/" title="→ 查看更多" class="btn btn-lg bg-white shadow-hover">→ 查看更多</a>
        </div>
      
    </div>
  </section>


    </section>
    <footer class="footer pt-5 mt-5">
  <div class="container">
    <div class="py-3">
      <div class="row justify-content-between">
        <div class="col-6">
          <img class="filter-gray mb-3 lazyload" height="40" data-src="/images/brand.svg" alt="AI架构 | AI系统基础架构设计与优化" role="img">
          <p class="mb-4">这个网站旨在为AI架构师和对AI系统设计和优化感兴趣的人提供有价值的信息和资源。我们提供关于AI架构设计原理、机器学习和深度学习算法、大规模数据处理技术等方面的深入文章、案例研究和最佳实践指南。通过这些内容，我们希望帮助读者了解如何构建高性能、可扩展的AI架构，并提供实用的建议和方法来优化AI系统的性能和可靠性。无论是初学者还是有经验的专业人士，我们致力于为您提供有益的见解和实用的资源，以推动AI架构领域的发展和进步。</p>
          <ul class="list-inline">
            
              <li class="list-inline-item">
                <a href="javascript:;">
                  <img 0="微信" src="/images/icons/contact_wechat.svg">
                </a>
              </li>
            
              <li class="list-inline-item">
                <a href="mailto:a@abc.com">
                  <img 0="邮箱" src="/images/icons/contact_email.svg">
                </a>
              </li>
            
          </ul>
        </div>
        <div class="col-4">
          <h5>友情链接</h5>
          <ul class="list-inline">
            
              <li class="list-inline-item">
                <a href="https://acorn.imaging.xin/" title="Acorn" target="_blank" rel="noopener">Acorn</a>
              </li>
            
              <li class="list-inline-item">
                <a href="https://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
              </li>
            
              <li class="list-inline-item">
                <a href="https://github.com/" title="GitHub" target="_blank" rel="noopener">GitHub</a>
              </li>
            
              <li class="list-inline-item">
                <a href="https://duoyu.wang/" title="To Base64" target="_blank" rel="noopener">To Base64</a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
    <hr class="hr" style="opacity: .25;">
    <div class="pt-3 pb-5">
      <ul class="list-inline mb-0 text-center">
        <li class="list-inline-item">&copy; 2023 AI架构 | AI系统基础架构设计与优化</li>
        
        <li class="list-inline-item">Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
        <li class="list-inline-item">Designer <a href="https://acorn.imaging.xin/" target="_blank">罗平</a></li>
      </ul>
    </div>
  </div>
</footer>
  </main>
  <div id="mobile-nav-dimmer"></div>
<div id="mobile-nav">
	<div id="mobile-nav-inner">
		<ul class="mobile-nav">
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/">首页</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/stories">案例</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/archives">文章</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/about">关于</a>
  </li>
  
</ul>
		
	</div>
</div>

  <script src="/libs/feather/feather.min.js"></script>
<script src="/libs/lazysizes/lazysizes.min.js"></script>

	<script src="/libs/tocbot/tocbot.min.js"></script>
	<script>
    tocbot.init({
      // Where to render the table of contents.
      tocSelector: '.js-toc',
      // Where to grab the headings to build the table of contents.
      contentSelector: '.js-toc-content',
      // Which headings to grab inside of the contentSelector element.
      headingSelector: 'h2, h3',
      // For headings inside relative or absolute positioned containers within content.
      hasInnerContainers: true,
    });
	</script>





<script src="/js/mobile-nav.js"></script>


<script src="/js/script.js"></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178892506-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178892506-1');
</script>
</body>
</html>